{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "543c9ac217bd4fdb93931b1313bbf251",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "### Exploring DBSCAN, K-Means, & Agglomerative Clustering to find the optimum number of clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cell_id": "71768aac6bab4190ad06e99aba2f443d",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 0,
    "execution_start": 1665280718837,
    "source_hash": "bbfc2aff"
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.cluster import KMeans, DBSCAN\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics.cluster import silhouette_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.4.1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# need version 1.4.1 to get read_pickle method to work\n",
    "pd.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cell_id": "d1b47b5050fb45b5b8a5c37c0d67689c",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 1718,
    "execution_start": 1665280718838,
    "source_hash": "f0943f1e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station</th>\n",
       "      <th>time</th>\n",
       "      <th>temp</th>\n",
       "      <th>dwpt</th>\n",
       "      <th>rhum</th>\n",
       "      <th>prcp</th>\n",
       "      <th>wdir</th>\n",
       "      <th>wspd</th>\n",
       "      <th>pres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3526502</th>\n",
       "      <td>KY510</td>\n",
       "      <td>2022-07-12 11:00:00</td>\n",
       "      <td>14.6</td>\n",
       "      <td>14.6</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>260.0</td>\n",
       "      <td>7.6</td>\n",
       "      <td>1013.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2706398</th>\n",
       "      <td>KMPZ0</td>\n",
       "      <td>2022-01-02 20:00:00</td>\n",
       "      <td>-11.0</td>\n",
       "      <td>-17.1</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>320.0</td>\n",
       "      <td>7.6</td>\n",
       "      <td>1027.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>727848</th>\n",
       "      <td>72551</td>\n",
       "      <td>2022-07-26 11:00:00</td>\n",
       "      <td>19.4</td>\n",
       "      <td>16.1</td>\n",
       "      <td>81.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1014.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        station                time  temp  dwpt   rhum  prcp   wdir  wspd  \\\n",
       "3526502   KY510 2022-07-12 11:00:00  14.6  14.6  100.0   0.0  260.0   7.6   \n",
       "2706398   KMPZ0 2022-01-02 20:00:00 -11.0 -17.1   61.0   0.0  320.0   7.6   \n",
       "727848    72551 2022-07-26 11:00:00  19.4  16.1   81.0   0.0  130.0  13.0   \n",
       "\n",
       "           pres  \n",
       "3526502  1013.0  \n",
       "2706398  1027.0  \n",
       "727848   1014.7  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get location from clean pickel file\n",
    "cln_pkl_loc = Path('cleanweathersmall.pkl')\n",
    "# load it onto df\n",
    "df = pd.read_pickle(cln_pkl_loc)\n",
    "# quick look at the df\n",
    "df.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collapse All Features -- Use Average"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "d428cacee2144610af83484bb9ff182c",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "## Apply DBSCAN Algorithm to create clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create clusters by grouping all stations by month and by hours based on datestamps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop thru all twelve months:\n",
    "DBSCAN_list = [] # = pd.DataFrame()\n",
    "for mth in range(1,13):\n",
    "    # loop thru all 24 hours\n",
    "    for hr in range(24):\n",
    "        # query df based on month and time\n",
    "        tmp_df = df.query(f'time.dt.hour == {hr} and time.dt.month == {mth}')\n",
    "        # remove time variable from df\n",
    "        tmp_df = tmp_df.loc[: , tmp_df.columns != 'time']\n",
    "        # calculate mean of such datafrme\n",
    "        tmp_df = tmp_df.groupby('station').mean()\n",
    "        # drop null values\n",
    "        tmp_df.dropna(inplace=True)\n",
    "        # if we get a result, calculate DBSCAN clusters\n",
    "        if not tmp_df.empty:\n",
    "            # rescale the data to zero mean and unit variance\n",
    "            scaler = StandardScaler()\n",
    "            scaler.fit(tmp_df)\n",
    "            X_scaled = scaler.transform(tmp_df)\n",
    "            # create the DBSCAN object; use all processors available\n",
    "            dbscan = DBSCAN(n_jobs=-1)\n",
    "            # run the DBSCAN algorithm\n",
    "            clusters = dbscan.fit_predict(X_scaled)\n",
    "            # attache clusters to df\n",
    "            tmp_df['DBSCAN_cluster'] = clusters\n",
    "            # add month and hour as variables\n",
    "            tmp_df['hr'], tmp_df['mth'] = hr, mth\n",
    "            # calculate the silhouette score; only if they're not outliers\n",
    "            tmp_df['silhouette_score'] = -1\n",
    "            if set(clusters) != {-1}:\n",
    "                tmp_df['silhouette_score'] = silhouette_score(X_scaled, clusters)                \n",
    "            # collect all dfs\n",
    "            DBSCAN_list.append(tmp_df)\n",
    "            \n",
    "# collect all DBSCAN dfs into one\n",
    "DBSCAN_df = pd.concat(DBSCAN_list)\n",
    "# reset the index; we can query the 'station' as a column much easier\n",
    "DBSCAN_df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select Clusters Where AA Belongs to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list the clusters where KARB0 shows up; exclude the -1 (outliers)\n",
    "AA_Clusters = DBSCAN_df.query('station == \"KARB0\" and DBSCAN_cluster != -1')['DBSCAN_cluster'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 3, 0, 1, 2])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AA_Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31,\n",
       " array(['0CNUO', '20QWH', '6URQB', '71850', 'DCBG8', 'MUKMN', 'NCUQS',\n",
       "        'UJHR7', 'VMWBN', 'UV7W2', 'V5792', '9W5OW', '71851', '8ZB0I',\n",
       "        'I0EZ7', '4DUJO', '9H92X', 'ATA0X', 'CTGT0', 'MAU7O', '71273',\n",
       "        '71667', 'CXQT0', 'L1YUU', 'LII7V', '71147', '71564', '71962',\n",
       "        'SJZBK', '71849', 'GCHAU'], dtype=object))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what stations make up these clusters?\n",
    "AA_near_stations = DBSCAN_df.query('DBSCAN_cluster in @AA_Clusters and silhouette_score > 0')['station'].unique()\n",
    "len(AA_near_stations), AA_near_stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export df with clusters; we'll use these results for K-Means\n",
    "DBSCAN_df.to_pickle('DBSCAN_clusters.pkl')"
   ]
  }
 ],
 "metadata": {
  "deepnote": {},
  "deepnote_execution_queue": [],
  "deepnote_full_width": true,
  "deepnote_notebook_id": "c3919f07f93c4a608f75703c36f003b1",
  "deepnote_persisted_session": {
   "createdAt": "2022-10-08T23:32:22.754Z"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "408afe8ba0fc984a0cb44b0671c49e061cdfc3372c6fcbbfef2559eebb6b7013"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
