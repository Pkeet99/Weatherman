{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Station Supervised models\n",
    "\n",
    "## General Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn import linear_model\n",
    "from sklearn.dummy import DummyRegressor\n",
    "import altair as alt\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from skopt.space import Integer\n",
    "from skopt.utils import use_named_args\n",
    "import numpy as np\n",
    "from skopt import gp_minimize\n",
    "from skopt.plots import plot_convergence\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearnex import patch_sklearn\n",
    "patch_sklearn()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Small dataset (2022 only) \n",
    "### Get cleaned data from pickle file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ROOT_DIR = os.path.realpath(os.path.join(os.getcwd(), '..'))\n",
    "# cln_pkl_loc = os.path.join(ROOT_DIR, 'data_cleaning','cleanweathersmall.pkl')\n",
    "cln_pkl_loc = os.path.join(ROOT_DIR, 'data','cleanweathersmall.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 3657000 entries, 0 to 3656999\n",
      "Data columns (total 9 columns):\n",
      " #   Column   Dtype         \n",
      "---  ------   -----         \n",
      " 0   station  object        \n",
      " 1   time     datetime64[ns]\n",
      " 2   temp     float64       \n",
      " 3   dwpt     float64       \n",
      " 4   rhum     float64       \n",
      " 5   prcp     float64       \n",
      " 6   wdir     float64       \n",
      " 7   wspd     float64       \n",
      " 8   pres     float64       \n",
      "dtypes: datetime64[ns](1), float64(7), object(1)\n",
      "memory usage: 279.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_pickle(cln_pkl_loc)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic data cleaning to build necessary features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                     temp_0CNUO  temp_0CO7B  temp_0FV1F  temp_1J1PJ  \\\ntime                                                                  \n2022-01-01 00:00:00       -25.1         5.0         1.2        -0.9   \n2022-01-01 01:00:00       -25.7         5.1         0.9        -0.6   \n2022-01-01 02:00:00       -26.2         4.2         1.5        -0.8   \n2022-01-01 03:00:00       -26.1         5.5         4.1        -0.9   \n2022-01-01 04:00:00       -26.5         5.9         3.1        -1.2   \n...                         ...         ...         ...         ...   \n2022-09-22 19:00:00        12.4        17.8        13.7        11.5   \n2022-09-22 20:00:00        13.0        17.0        14.3        12.0   \n2022-09-22 21:00:00        13.2        16.6        13.9        12.4   \n2022-09-22 22:00:00        11.9        16.2        12.4        12.5   \n2022-09-22 23:00:00        11.3        15.9        11.5        11.6   \n\n                     temp_1JWST  temp_20QWH  temp_21O3U  temp_2W8UZ  \\\ntime                                                                  \n2022-01-01 00:00:00        -6.5       -28.7       -29.0         4.6   \n2022-01-01 01:00:00        -7.5       -29.5       -28.9         4.6   \n2022-01-01 02:00:00        -8.6       -30.2       -30.1         4.7   \n2022-01-01 03:00:00        -9.4       -29.9       -30.1         4.6   \n2022-01-01 04:00:00       -10.1       -30.4       -31.4         4.9   \n...                         ...         ...         ...         ...   \n2022-09-22 19:00:00        10.2        13.5        12.5        15.2   \n2022-09-22 20:00:00        10.4        14.0        12.5        14.8   \n2022-09-22 21:00:00        10.5        14.3        12.4        15.1   \n2022-09-22 22:00:00         9.9        13.5        12.7        14.4   \n2022-09-22 23:00:00         7.2        12.8        12.0        13.5   \n\n                     temp_3S56J  temp_4DUJO  ...  pres_O879F  pres_QHA0T  \\\ntime                                         ...                           \n2022-01-01 00:00:00       -26.5         1.8  ...      1009.4      1013.2   \n2022-01-01 01:00:00       -27.3         1.6  ...      1009.0      1014.2   \n2022-01-01 02:00:00       -27.9         0.9  ...      1007.4      1014.5   \n2022-01-01 03:00:00       -28.1         1.0  ...      1007.2      1015.3   \n2022-01-01 04:00:00       -28.6         0.5  ...      1006.6      1016.1   \n...                         ...         ...  ...         ...         ...   \n2022-09-22 19:00:00        10.8        12.4  ...      1014.3      1022.6   \n2022-09-22 20:00:00        11.4        11.6  ...      1014.5      1022.4   \n2022-09-22 21:00:00        11.7        10.8  ...      1014.9      1022.2   \n2022-09-22 22:00:00        11.8         9.9  ...      1015.6      1021.3   \n2022-09-22 23:00:00        10.4         8.8  ...      1016.1      1021.1   \n\n                     pres_SJZBK  pres_UJHR7  pres_UV7W2  pres_V5792  \\\ntime                                                                  \n2022-01-01 00:00:00      1025.5      1021.0      1023.8      1019.9   \n2022-01-01 01:00:00      1026.0      1022.3      1024.5      1020.8   \n2022-01-01 02:00:00      1026.3      1023.0      1024.9      1021.2   \n2022-01-01 03:00:00      1026.3      1023.9      1025.2      1022.1   \n2022-01-01 04:00:00      1026.4      1024.4      1025.2      1022.9   \n...                         ...         ...         ...         ...   \n2022-09-22 19:00:00      1023.0      1025.5      1024.7      1024.6   \n2022-09-22 20:00:00      1021.5      1024.8      1023.5      1023.8   \n2022-09-22 21:00:00      1020.6      1023.9      1022.9      1023.7   \n2022-09-22 22:00:00      1019.3      1022.8      1021.8      1023.0   \n2022-09-22 23:00:00      1018.4      1022.0      1021.0      1022.6   \n\n                     pres_VMWBN  pres_XM44W  pres_ZFZUV  pres_ZWC6W  \ntime                                                                 \n2022-01-01 00:00:00      1022.6      1013.5      1023.8      1010.8  \n2022-01-01 01:00:00      1023.4      1014.6      1024.2      1011.8  \n2022-01-01 02:00:00      1024.0      1015.1      1024.9      1012.7  \n2022-01-01 03:00:00      1024.5      1016.0      1025.4      1013.6  \n2022-01-01 04:00:00      1024.8      1017.3      1025.4      1013.9  \n...                         ...         ...         ...         ...  \n2022-09-22 19:00:00      1025.0      1022.6      1024.5      1017.8  \n2022-09-22 20:00:00      1023.7      1022.4      1023.1      1017.9  \n2022-09-22 21:00:00      1023.1      1022.2      1022.0      1018.1  \n2022-09-22 22:00:00      1021.9      1021.9      1021.1      1018.4  \n2022-09-22 23:00:00      1021.1      1021.8      1020.3      1018.6  \n\n[6360 rows x 4025 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>temp_0CNUO</th>\n      <th>temp_0CO7B</th>\n      <th>temp_0FV1F</th>\n      <th>temp_1J1PJ</th>\n      <th>temp_1JWST</th>\n      <th>temp_20QWH</th>\n      <th>temp_21O3U</th>\n      <th>temp_2W8UZ</th>\n      <th>temp_3S56J</th>\n      <th>temp_4DUJO</th>\n      <th>...</th>\n      <th>pres_O879F</th>\n      <th>pres_QHA0T</th>\n      <th>pres_SJZBK</th>\n      <th>pres_UJHR7</th>\n      <th>pres_UV7W2</th>\n      <th>pres_V5792</th>\n      <th>pres_VMWBN</th>\n      <th>pres_XM44W</th>\n      <th>pres_ZFZUV</th>\n      <th>pres_ZWC6W</th>\n    </tr>\n    <tr>\n      <th>time</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2022-01-01 00:00:00</th>\n      <td>-25.1</td>\n      <td>5.0</td>\n      <td>1.2</td>\n      <td>-0.9</td>\n      <td>-6.5</td>\n      <td>-28.7</td>\n      <td>-29.0</td>\n      <td>4.6</td>\n      <td>-26.5</td>\n      <td>1.8</td>\n      <td>...</td>\n      <td>1009.4</td>\n      <td>1013.2</td>\n      <td>1025.5</td>\n      <td>1021.0</td>\n      <td>1023.8</td>\n      <td>1019.9</td>\n      <td>1022.6</td>\n      <td>1013.5</td>\n      <td>1023.8</td>\n      <td>1010.8</td>\n    </tr>\n    <tr>\n      <th>2022-01-01 01:00:00</th>\n      <td>-25.7</td>\n      <td>5.1</td>\n      <td>0.9</td>\n      <td>-0.6</td>\n      <td>-7.5</td>\n      <td>-29.5</td>\n      <td>-28.9</td>\n      <td>4.6</td>\n      <td>-27.3</td>\n      <td>1.6</td>\n      <td>...</td>\n      <td>1009.0</td>\n      <td>1014.2</td>\n      <td>1026.0</td>\n      <td>1022.3</td>\n      <td>1024.5</td>\n      <td>1020.8</td>\n      <td>1023.4</td>\n      <td>1014.6</td>\n      <td>1024.2</td>\n      <td>1011.8</td>\n    </tr>\n    <tr>\n      <th>2022-01-01 02:00:00</th>\n      <td>-26.2</td>\n      <td>4.2</td>\n      <td>1.5</td>\n      <td>-0.8</td>\n      <td>-8.6</td>\n      <td>-30.2</td>\n      <td>-30.1</td>\n      <td>4.7</td>\n      <td>-27.9</td>\n      <td>0.9</td>\n      <td>...</td>\n      <td>1007.4</td>\n      <td>1014.5</td>\n      <td>1026.3</td>\n      <td>1023.0</td>\n      <td>1024.9</td>\n      <td>1021.2</td>\n      <td>1024.0</td>\n      <td>1015.1</td>\n      <td>1024.9</td>\n      <td>1012.7</td>\n    </tr>\n    <tr>\n      <th>2022-01-01 03:00:00</th>\n      <td>-26.1</td>\n      <td>5.5</td>\n      <td>4.1</td>\n      <td>-0.9</td>\n      <td>-9.4</td>\n      <td>-29.9</td>\n      <td>-30.1</td>\n      <td>4.6</td>\n      <td>-28.1</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>1007.2</td>\n      <td>1015.3</td>\n      <td>1026.3</td>\n      <td>1023.9</td>\n      <td>1025.2</td>\n      <td>1022.1</td>\n      <td>1024.5</td>\n      <td>1016.0</td>\n      <td>1025.4</td>\n      <td>1013.6</td>\n    </tr>\n    <tr>\n      <th>2022-01-01 04:00:00</th>\n      <td>-26.5</td>\n      <td>5.9</td>\n      <td>3.1</td>\n      <td>-1.2</td>\n      <td>-10.1</td>\n      <td>-30.4</td>\n      <td>-31.4</td>\n      <td>4.9</td>\n      <td>-28.6</td>\n      <td>0.5</td>\n      <td>...</td>\n      <td>1006.6</td>\n      <td>1016.1</td>\n      <td>1026.4</td>\n      <td>1024.4</td>\n      <td>1025.2</td>\n      <td>1022.9</td>\n      <td>1024.8</td>\n      <td>1017.3</td>\n      <td>1025.4</td>\n      <td>1013.9</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2022-09-22 19:00:00</th>\n      <td>12.4</td>\n      <td>17.8</td>\n      <td>13.7</td>\n      <td>11.5</td>\n      <td>10.2</td>\n      <td>13.5</td>\n      <td>12.5</td>\n      <td>15.2</td>\n      <td>10.8</td>\n      <td>12.4</td>\n      <td>...</td>\n      <td>1014.3</td>\n      <td>1022.6</td>\n      <td>1023.0</td>\n      <td>1025.5</td>\n      <td>1024.7</td>\n      <td>1024.6</td>\n      <td>1025.0</td>\n      <td>1022.6</td>\n      <td>1024.5</td>\n      <td>1017.8</td>\n    </tr>\n    <tr>\n      <th>2022-09-22 20:00:00</th>\n      <td>13.0</td>\n      <td>17.0</td>\n      <td>14.3</td>\n      <td>12.0</td>\n      <td>10.4</td>\n      <td>14.0</td>\n      <td>12.5</td>\n      <td>14.8</td>\n      <td>11.4</td>\n      <td>11.6</td>\n      <td>...</td>\n      <td>1014.5</td>\n      <td>1022.4</td>\n      <td>1021.5</td>\n      <td>1024.8</td>\n      <td>1023.5</td>\n      <td>1023.8</td>\n      <td>1023.7</td>\n      <td>1022.4</td>\n      <td>1023.1</td>\n      <td>1017.9</td>\n    </tr>\n    <tr>\n      <th>2022-09-22 21:00:00</th>\n      <td>13.2</td>\n      <td>16.6</td>\n      <td>13.9</td>\n      <td>12.4</td>\n      <td>10.5</td>\n      <td>14.3</td>\n      <td>12.4</td>\n      <td>15.1</td>\n      <td>11.7</td>\n      <td>10.8</td>\n      <td>...</td>\n      <td>1014.9</td>\n      <td>1022.2</td>\n      <td>1020.6</td>\n      <td>1023.9</td>\n      <td>1022.9</td>\n      <td>1023.7</td>\n      <td>1023.1</td>\n      <td>1022.2</td>\n      <td>1022.0</td>\n      <td>1018.1</td>\n    </tr>\n    <tr>\n      <th>2022-09-22 22:00:00</th>\n      <td>11.9</td>\n      <td>16.2</td>\n      <td>12.4</td>\n      <td>12.5</td>\n      <td>9.9</td>\n      <td>13.5</td>\n      <td>12.7</td>\n      <td>14.4</td>\n      <td>11.8</td>\n      <td>9.9</td>\n      <td>...</td>\n      <td>1015.6</td>\n      <td>1021.3</td>\n      <td>1019.3</td>\n      <td>1022.8</td>\n      <td>1021.8</td>\n      <td>1023.0</td>\n      <td>1021.9</td>\n      <td>1021.9</td>\n      <td>1021.1</td>\n      <td>1018.4</td>\n    </tr>\n    <tr>\n      <th>2022-09-22 23:00:00</th>\n      <td>11.3</td>\n      <td>15.9</td>\n      <td>11.5</td>\n      <td>11.6</td>\n      <td>7.2</td>\n      <td>12.8</td>\n      <td>12.0</td>\n      <td>13.5</td>\n      <td>10.4</td>\n      <td>8.8</td>\n      <td>...</td>\n      <td>1016.1</td>\n      <td>1021.1</td>\n      <td>1018.4</td>\n      <td>1022.0</td>\n      <td>1021.0</td>\n      <td>1022.6</td>\n      <td>1021.1</td>\n      <td>1021.8</td>\n      <td>1020.3</td>\n      <td>1018.6</td>\n    </tr>\n  </tbody>\n</table>\n<p>6360 rows × 4025 columns</p>\n</div>"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pivoted_df = df.pivot(index='time', columns='station', values=['temp', 'dwpt','rhum','prcp','wdir','wspd','pres'])\n",
    "pivoted_df.columns = ['_'.join(col) for col in pivoted_df.columns.values]\n",
    "pivoted_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our target is Ann Arbor which is station __\"KARB0\"__, so pulling those features out. And we want to predict the weather 24 hours in the future, so need to duplicate and shift the features while doing some more basic cleaning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                     temp_KARB0  dwpt_KARB0  rhum_KARB0  prcp_KARB0  \\\n2022-01-01 00:00:00         5.0         2.9        86.0         0.0   \n2022-01-01 01:00:00         5.0         2.9        86.0         0.0   \n2022-01-01 02:00:00         5.0         2.9        86.0         0.0   \n2022-01-01 03:00:00         5.0         2.9        86.0         0.0   \n2022-01-01 04:00:00         5.6         3.3        85.0         0.0   \n\n                     wdir_KARB0  wspd_KARB0  pres_KARB0  24 hr~temp_KARB0  \\\n2022-01-01 00:00:00       120.0        11.0      1005.0              -2.2   \n2022-01-01 01:00:00       120.0        11.2      1005.4              -2.8   \n2022-01-01 02:00:00       120.0         5.4      1005.3              -3.3   \n2022-01-01 03:00:00         0.0         0.0      1004.9              -3.9   \n2022-01-01 04:00:00         0.0         0.0      1004.9              -4.4   \n\n                     24 hr~dwpt_KARB0  24 hr~rhum_KARB0  24 hr~prcp_KARB0  \\\n2022-01-01 00:00:00              -3.9              88.0               0.6   \n2022-01-01 01:00:00              -5.6              81.0               0.7   \n2022-01-01 02:00:00              -5.6              84.0               0.4   \n2022-01-01 03:00:00              -6.1              85.0               0.3   \n2022-01-01 04:00:00              -6.1              88.0               0.3   \n\n                     24 hr~wdir_KARB0  24 hr~wspd_KARB0  24 hr~pres_KARB0  \n2022-01-01 00:00:00              50.0              16.6            1010.0  \n2022-01-01 01:00:00              30.0              16.6            1010.2  \n2022-01-01 02:00:00              30.0              24.1            1009.9  \n2022-01-01 03:00:00              20.0              18.4            1010.3  \n2022-01-01 04:00:00              30.0              16.6            1010.1  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>temp_KARB0</th>\n      <th>dwpt_KARB0</th>\n      <th>rhum_KARB0</th>\n      <th>prcp_KARB0</th>\n      <th>wdir_KARB0</th>\n      <th>wspd_KARB0</th>\n      <th>pres_KARB0</th>\n      <th>24 hr~temp_KARB0</th>\n      <th>24 hr~dwpt_KARB0</th>\n      <th>24 hr~rhum_KARB0</th>\n      <th>24 hr~prcp_KARB0</th>\n      <th>24 hr~wdir_KARB0</th>\n      <th>24 hr~wspd_KARB0</th>\n      <th>24 hr~pres_KARB0</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2022-01-01 00:00:00</th>\n      <td>5.0</td>\n      <td>2.9</td>\n      <td>86.0</td>\n      <td>0.0</td>\n      <td>120.0</td>\n      <td>11.0</td>\n      <td>1005.0</td>\n      <td>-2.2</td>\n      <td>-3.9</td>\n      <td>88.0</td>\n      <td>0.6</td>\n      <td>50.0</td>\n      <td>16.6</td>\n      <td>1010.0</td>\n    </tr>\n    <tr>\n      <th>2022-01-01 01:00:00</th>\n      <td>5.0</td>\n      <td>2.9</td>\n      <td>86.0</td>\n      <td>0.0</td>\n      <td>120.0</td>\n      <td>11.2</td>\n      <td>1005.4</td>\n      <td>-2.8</td>\n      <td>-5.6</td>\n      <td>81.0</td>\n      <td>0.7</td>\n      <td>30.0</td>\n      <td>16.6</td>\n      <td>1010.2</td>\n    </tr>\n    <tr>\n      <th>2022-01-01 02:00:00</th>\n      <td>5.0</td>\n      <td>2.9</td>\n      <td>86.0</td>\n      <td>0.0</td>\n      <td>120.0</td>\n      <td>5.4</td>\n      <td>1005.3</td>\n      <td>-3.3</td>\n      <td>-5.6</td>\n      <td>84.0</td>\n      <td>0.4</td>\n      <td>30.0</td>\n      <td>24.1</td>\n      <td>1009.9</td>\n    </tr>\n    <tr>\n      <th>2022-01-01 03:00:00</th>\n      <td>5.0</td>\n      <td>2.9</td>\n      <td>86.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1004.9</td>\n      <td>-3.9</td>\n      <td>-6.1</td>\n      <td>85.0</td>\n      <td>0.3</td>\n      <td>20.0</td>\n      <td>18.4</td>\n      <td>1010.3</td>\n    </tr>\n    <tr>\n      <th>2022-01-01 04:00:00</th>\n      <td>5.6</td>\n      <td>3.3</td>\n      <td>85.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1004.9</td>\n      <td>-4.4</td>\n      <td>-6.1</td>\n      <td>88.0</td>\n      <td>0.3</td>\n      <td>30.0</td>\n      <td>16.6</td>\n      <td>1010.1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann_arbor_cols = [col for col in pivoted_df.columns if \"KARB0\" in col]\n",
    "ann_arbor_df = pivoted_df[ann_arbor_cols].copy()\n",
    "for col in ann_arbor_df.columns:\n",
    "    ann_arbor_df[f'24 hr~{col}'] = ann_arbor_df[col].shift(-24)\n",
    "ann_arbor_df = ann_arbor_df.rename_axis(None, axis = 0)\n",
    "ann_arbor_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We need to merge the new features with the main dataframe so we have not only the Ann Arbor measurements, but also all measurements from surrounding stations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6336, 4039)\n"
     ]
    }
   ],
   "source": [
    "pred_df = pd.merge(pivoted_df,ann_arbor_df, left_index=True, right_index=True)\n",
    "pred_df = pred_df[pred_df['24 hr~temp_KARB0'].notna()]\n",
    "print(pred_df.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "~~### There are a lot of features with excessive amounts of null values to get rid of. Dropping any with more than 500 missing values still leaves a sufficient number of features for predicting~~\n",
    "### Correction\n",
    "Used interpolation in cleaning model to fill na, no longer need this cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# to_drop = []\n",
    "# for col in pred_df.columns:\n",
    "#     num = pred_df[col].isna().sum()\n",
    "#     if num > 500:\n",
    "#         # print(f\"{col} has {num} missing values\")\n",
    "#         to_drop.append(col)\n",
    "# pred_df.drop(columns=to_drop,inplace=True)\n",
    "# # pred_df.dropna(inplace=True)\n",
    "\n",
    "# for i in pred_df.columns[pred_df.isnull().any(axis=0)]:     #---Applying Only on variables with NaN values\n",
    "#     pred_df[i].fillna(pred_df[i].mean(),inplace=True)\n",
    "# pred_df.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now our target will be the '-24hr~temp_KARB0' column, and our features to use in our first prediction model will be all of the measurements at every surrounding station 24 hours prior to our target.\n",
    "This cell will run 5 fold cross-validate on our 3 chosen regression models (Extra Trees Regressor, Lasso Regressor, and Tweedie Regressor). This will show how the average accuracy scores compare across these models on this data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extra Trees Regressor\n",
      "Mean accuracy score: 0.983, best accuracy score: 0.984, with std dev of: 0.001\n",
      "Mean training time: 0.105\n",
      "Score on hold out set: 0.986\n",
      "**************\n",
      "Lasso Regressor\n",
      "Mean accuracy score: 0.962, best accuracy score: 0.966, with std dev of: 0.003\n",
      "Mean training time: 0.034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\jesse\\onedrive\\documents\\homework\\mich\\521\\ms2_git\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but Lasso was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score on hold out set: 0.961\n",
      "**************\n",
      "Tweedie Regressor\n",
      "Mean accuracy score: 0.944, best accuracy score: 0.952, with std dev of: 0.006\n",
      "Mean training time: 0.029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\jesse\\onedrive\\documents\\homework\\mich\\521\\ms2_git\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:294: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score on hold out set: 0.94\n",
      "**************\n",
      "Dummy Regressor\n",
      "Mean accuracy score: -0.029, best accuracy score: -0.02, with std dev of: 0.007\n",
      "Mean training time: 0.0\n",
      "Score on hold out set: -0.029\n",
      "**************\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "X_cols = [col for col in pred_df.columns if \"~\" not in col]\n",
    "X = pred_df[X_cols]\n",
    "y = pred_df['24 hr~temp_KARB0']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=696)\n",
    "xt_reg = ExtraTreesRegressor(random_state=696,n_jobs=-1)\n",
    "lasso_reg = linear_model.Lasso(alpha=0.1,max_iter=1500)\n",
    "tw_reg = linear_model.TweedieRegressor(max_iter=250)\n",
    "dummy_reg = DummyRegressor(strategy=\"median\")\n",
    "models = {'Extra Trees Regressor':xt_reg,\n",
    "          'Lasso Regressor':lasso_reg,\n",
    "          'Tweedie Regressor':tw_reg,\n",
    "          'Dummy Regressor':dummy_reg}\n",
    "for key, value in models.items():\n",
    "    # value = make_pipeline(StandardScaler(), value)\n",
    "    cv_results = cross_validate(value, X_train, y_train, cv=5,n_jobs=-1)\n",
    "    print(key)\n",
    "    print(\"Mean accuracy score: \", end=\"\")\n",
    "    print(round(cv_results['test_score'].mean(),3), end=\"\")\n",
    "    print(\", best accuracy score: \", end=\"\")\n",
    "    print(round(cv_results['test_score'].max(),3), end=\"\")\n",
    "    print(\", with std dev of: \", end=\"\")\n",
    "    print(round(cv_results['test_score'].std(),3))\n",
    "    print(\"Mean training time: \", end=\"\")\n",
    "    print(round(cv_results['score_time'].mean(),3))\n",
    "    print(f\"Score on hold out set: {round(value.fit(X_train, y_train).score(X_test, y_test),3)}\")\n",
    "    print(\"**************\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examine the feature importances in the best performing model (Extra Trees Regressor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "        Feature Importance\n371  temp_KISW0   0.050285\n142  temp_72741   0.044355\n521  temp_KTOB0   0.038855\n405  temp_KMFI0   0.037328\n271  temp_KD250   0.036743\n486  temp_KRHI0   0.032733\n385  temp_KLNL0    0.02905\n244  temp_KC350   0.028726\n208  temp_KARV0    0.02872\n315  temp_KFKA0   0.028612",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Feature</th>\n      <th>Importance</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>371</th>\n      <td>temp_KISW0</td>\n      <td>0.050285</td>\n    </tr>\n    <tr>\n      <th>142</th>\n      <td>temp_72741</td>\n      <td>0.044355</td>\n    </tr>\n    <tr>\n      <th>521</th>\n      <td>temp_KTOB0</td>\n      <td>0.038855</td>\n    </tr>\n    <tr>\n      <th>405</th>\n      <td>temp_KMFI0</td>\n      <td>0.037328</td>\n    </tr>\n    <tr>\n      <th>271</th>\n      <td>temp_KD250</td>\n      <td>0.036743</td>\n    </tr>\n    <tr>\n      <th>486</th>\n      <td>temp_KRHI0</td>\n      <td>0.032733</td>\n    </tr>\n    <tr>\n      <th>385</th>\n      <td>temp_KLNL0</td>\n      <td>0.02905</td>\n    </tr>\n    <tr>\n      <th>244</th>\n      <td>temp_KC350</td>\n      <td>0.028726</td>\n    </tr>\n    <tr>\n      <th>208</th>\n      <td>temp_KARV0</td>\n      <td>0.02872</td>\n    </tr>\n    <tr>\n      <th>315</th>\n      <td>temp_KFKA0</td>\n      <td>0.028612</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importance_df = pd.DataFrame([X.columns, xt_reg.feature_importances_]).transpose()\n",
    "feature_importance_df.columns = ['Feature', 'Importance']\n",
    "feature_importance_df.sort_values('Importance',ascending=False,inplace=True)\n",
    "feature_importance_df.to_csv(\"small_basic_features.csv\",index=False)\n",
    "feature_importance_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": "\n<div id=\"altair-viz-186ca73b86984e4dbe3bcd13ef063923\"></div>\n<script type=\"text/javascript\">\n  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n  (function(spec, embedOpt){\n    let outputDiv = document.currentScript.previousElementSibling;\n    if (outputDiv.id !== \"altair-viz-186ca73b86984e4dbe3bcd13ef063923\") {\n      outputDiv = document.getElementById(\"altair-viz-186ca73b86984e4dbe3bcd13ef063923\");\n    }\n    const paths = {\n      \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\",\n      \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\",\n      \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.17.0?noext\",\n      \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\",\n    };\n\n    function maybeLoadScript(lib, version) {\n      var key = `${lib.replace(\"-\", \"\")}_version`;\n      return (VEGA_DEBUG[key] == version) ?\n        Promise.resolve(paths[lib]) :\n        new Promise(function(resolve, reject) {\n          var s = document.createElement('script');\n          document.getElementsByTagName(\"head\")[0].appendChild(s);\n          s.async = true;\n          s.onload = () => {\n            VEGA_DEBUG[key] = version;\n            return resolve(paths[lib]);\n          };\n          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n          s.src = paths[lib];\n        });\n    }\n\n    function showError(err) {\n      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n      throw err;\n    }\n\n    function displayChart(vegaEmbed) {\n      vegaEmbed(outputDiv, spec, embedOpt)\n        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n    }\n\n    if(typeof define === \"function\" && define.amd) {\n      requirejs.config({paths});\n      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n    } else {\n      maybeLoadScript(\"vega\", \"5\")\n        .then(() => maybeLoadScript(\"vega-lite\", \"4.17.0\"))\n        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n        .catch(showError)\n        .then(() => displayChart(vegaEmbed));\n    }\n  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-677093001763858cca79ca97d4e37b68\"}, \"mark\": \"bar\", \"encoding\": {\"x\": {\"axis\": {\"format\": \"%\", \"labelFontSize\": 12, \"tickSize\": 0}, \"field\": \"Importance\", \"type\": \"quantitative\"}, \"y\": {\"axis\": {\"labelFontSize\": 12, \"labelPadding\": 10, \"tickSize\": 0}, \"field\": \"Feature\", \"sort\": [\"temp_KISW0\", \"temp_72741\", \"temp_KTOB0\", \"temp_KMFI0\", \"temp_KD250\"], \"title\": \"\", \"type\": \"nominal\"}}, \"height\": 200, \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.17.0.json\", \"datasets\": {\"data-677093001763858cca79ca97d4e37b68\": [{\"Feature\": \"temp_KISW0\", \"Importance\": 0.05028531896990663}, {\"Feature\": \"temp_72741\", \"Importance\": 0.04435494550849216}, {\"Feature\": \"temp_KTOB0\", \"Importance\": 0.03885483956239575}, {\"Feature\": \"temp_KMFI0\", \"Importance\": 0.037327873059029716}, {\"Feature\": \"temp_KD250\", \"Importance\": 0.03674266970774281}]}}, {\"mode\": \"vega-lite\"});\n</script>",
      "text/plain": "alt.Chart(...)"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import altair as alt\n",
    "alt.Chart(feature_importance_df[:5]).mark_bar().encode(\n",
    "    x=alt.X('Importance:Q', axis=alt.Axis(format=\"%\", tickSize=0, labelFontSize=12)),\n",
    "    y=alt.Y(\n",
    "        'Feature:N', sort=list(feature_importance_df[:5].Feature), title=\"\",\n",
    "        axis=alt.Axis(tickSize=0, labelFontSize=12, labelPadding=10)),\n",
    ").properties(\n",
    "    height=200\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyper-parameter tuning the Extra Trees Regressor\n",
    "5 fold cross validate looking for the optimized estimators, depth, sample split, and sample leaf parameters. Evaluating the 'best' based on the mean squared error achieved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: -0.9828087448138512\n",
      "Best parameters:\n",
      " - n-estimators= 101\n",
      " - max_depth= 50\n",
      " - min_samples_split= 2\n",
      " - min_samples_leaf=  1\n"
     ]
    }
   ],
   "source": [
    "# %%timeit -r 1 -n 1\n",
    "space  = [Integer(100,200, name='n_estimators'),\n",
    "          Integer(1, 50, name='max_depth'),\n",
    "          Integer(2, 100, name='min_samples_split'),\n",
    "          Integer(1, 100, name='min_samples_leaf')]\n",
    "\n",
    "@use_named_args(space)\n",
    "def objective(**params):\n",
    "    xt_reg.set_params(**params)\n",
    "\n",
    "    return -np.mean(cross_val_score(xt_reg, X_train, y_train, cv=5, n_jobs=-1))\n",
    "\n",
    "res_gp = gp_minimize(objective, space, n_calls=15, random_state=696)\n",
    "\n",
    "print(f\"Best score: {res_gp.fun}\")\n",
    "print(\"Best parameters:\")\n",
    "print(f\" - n-estimators= {res_gp.x[0]}\")\n",
    "print(f\" - max_depth= {res_gp.x[1]}\")\n",
    "print(f\" - min_samples_split= {res_gp.x[2]}\")\n",
    "print(f\" - min_samples_leaf=  {res_gp.x[3]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the convergence for the above hypertuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<AxesSubplot:title={'center':'Convergence plot'}, xlabel='Number of calls $n$', ylabel='$\\\\min f(x)$ after $n$ calls'>"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_convergence(res_gp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final re-run of the Extra Trees Model with the tuned hyperparameters\n",
    "There is a very minor improvement on the accuracy score, with some pretty significant increases in training time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extra Trees Regressor\n",
      "Mean accuracy score: 0.983, best accuracy score: 0.984, with std dev of: 0.001\n",
      "Mean training time: 0.054\n",
      "Score on hold out set: 0.986\n",
      "**************\n"
     ]
    }
   ],
   "source": [
    "xt_reg = ExtraTreesRegressor(n_estimators=res_gp.x[0], \n",
    "                             max_depth=res_gp.x[1], \n",
    "                             min_samples_split=res_gp.x[2], \n",
    "                             min_samples_leaf=res_gp.x[3], \n",
    "                             random_state=696,n_jobs=-1\n",
    "                            )\n",
    "models = {'Extra Trees Regressor':xt_reg}\n",
    "for key, value in models.items():\n",
    "    cv_results = cross_validate(value, X_train, y_train, cv=5,n_jobs=-1)\n",
    "    print(key)\n",
    "    print(\"Mean accuracy score: \", end=\"\")\n",
    "    print(round(cv_results['test_score'].mean(),3), end=\"\")\n",
    "    print(\", best accuracy score: \", end=\"\")\n",
    "    print(round(cv_results['test_score'].max(),3), end=\"\")\n",
    "    print(\", with std dev of: \", end=\"\")\n",
    "    print(round(cv_results['test_score'].std(),3))\n",
    "    print(\"Mean training time: \", end=\"\")\n",
    "    print(round(cv_results['score_time'].mean(),3))\n",
    "    print(f\"Score on hold out set: {round(value.fit(X_train, y_train).score(X_test, y_test),3)}\")\n",
    "    print(\"**************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.DataFrame()\n",
    "final_df['Actual'] = y.values\n",
    "final_df['XT-pred'] = xt_reg.predict(X)\n",
    "final_df['Lo-pred'] = lasso_reg.predict(X)\n",
    "final_df['Tw-pred'] = tw_reg.predict(X)\n",
    "final_df['Dum-pred'] = dummy_reg.predict(X)\n",
    "final_df['TimeStamp'] = pred_df.index\n",
    "# final_df = final_df.melt(id_vars='TimeStamp')\n",
    "final_df.to_csv('small_basic_predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full US dataset (2019-Sept 2022)\n",
    "### Get cleaned data from pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ROOT_DIR = os.path.realpath(os.path.join(os.getcwd(), '..'))\n",
    "cln_pkl_loc = os.path.join(ROOT_DIR, 'data_cleaning','cleanweather.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 62183652 entries, 0 to 62183651\n",
      "Data columns (total 9 columns):\n",
      " #   Column   Dtype         \n",
      "---  ------   -----         \n",
      " 0   station  object        \n",
      " 1   time     datetime64[ns]\n",
      " 2   temp     float64       \n",
      " 3   dwpt     float64       \n",
      " 4   rhum     float64       \n",
      " 5   prcp     float64       \n",
      " 6   wdir     float64       \n",
      " 7   wspd     float64       \n",
      " 8   pres     float64       \n",
      "dtypes: datetime64[ns](1), float64(7), object(1)\n",
      "memory usage: 4.2+ GB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_pickle(cln_pkl_loc)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic data cleaning to build necessary features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                     temp_04AEH  temp_0CC8G  temp_0CNUO  temp_0CO7B  \\\ntime                                                                  \n2019-01-01 00:00:00         NaN         NaN         NaN         NaN   \n2019-01-01 01:00:00         NaN         NaN         NaN         NaN   \n2019-01-01 02:00:00         NaN         NaN         NaN         NaN   \n2019-01-01 03:00:00         NaN         NaN         NaN         NaN   \n2019-01-01 04:00:00         NaN         NaN         NaN         NaN   \n...                         ...         ...         ...         ...   \n2022-10-01 19:00:00        18.0        16.3        12.9        19.2   \n2022-10-01 20:00:00        18.0        15.5        13.4        19.2   \n2022-10-01 21:00:00        17.0        14.3        13.3        18.1   \n2022-10-01 22:00:00        14.0        13.1        13.2        17.0   \n2022-10-01 23:00:00        14.0        11.4        12.9        15.8   \n\n                     temp_0FV1F  temp_0FV2W  temp_0JM7R  temp_0JPFS  \\\ntime                                                                  \n2019-01-01 00:00:00         NaN         NaN         NaN         NaN   \n2019-01-01 01:00:00         NaN         NaN         NaN         NaN   \n2019-01-01 02:00:00         NaN         NaN         NaN         NaN   \n2019-01-01 03:00:00         NaN         NaN         NaN         NaN   \n2019-01-01 04:00:00         NaN         NaN         NaN         NaN   \n...                         ...         ...         ...         ...   \n2022-10-01 19:00:00        18.5         NaN         8.8        15.0   \n2022-10-01 20:00:00        18.4         NaN         8.4        14.4   \n2022-10-01 21:00:00        17.8         NaN         8.1        13.4   \n2022-10-01 22:00:00        16.9         NaN         7.0        11.5   \n2022-10-01 23:00:00        15.3         NaN         4.7         9.9   \n\n                     temp_0NNEW  temp_0RJDR  ...  pres_Z8Y0M  pres_ZFS01  \\\ntime                                         ...                           \n2019-01-01 00:00:00         NaN         NaN  ...         NaN         NaN   \n2019-01-01 01:00:00         NaN         NaN  ...         NaN         NaN   \n2019-01-01 02:00:00         NaN         NaN  ...         NaN         NaN   \n2019-01-01 03:00:00         NaN         NaN  ...         NaN         NaN   \n2019-01-01 04:00:00         NaN         NaN  ...         NaN         NaN   \n...                         ...         ...  ...         ...         ...   \n2022-10-01 19:00:00        21.4        22.1  ...      1020.0      1020.0   \n2022-10-01 20:00:00        24.0        22.5  ...      1021.0      1020.2   \n2022-10-01 21:00:00        21.8        21.9  ...      1020.0      1020.3   \n2022-10-01 22:00:00        21.2        23.2  ...      1020.0      1020.6   \n2022-10-01 23:00:00        19.4        22.2  ...      1020.0      1021.1   \n\n                     pres_ZFZUV  pres_ZJ8AR  pres_ZNWZW  pres_ZRBBD  \\\ntime                                                                  \n2019-01-01 00:00:00         NaN         NaN         NaN         NaN   \n2019-01-01 01:00:00         NaN         NaN         NaN         NaN   \n2019-01-01 02:00:00         NaN         NaN         NaN         NaN   \n2019-01-01 03:00:00         NaN         NaN         NaN         NaN   \n2019-01-01 04:00:00         NaN         NaN         NaN         NaN   \n...                         ...         ...         ...         ...   \n2022-10-01 19:00:00      1027.2      1014.3      1018.6      1020.9   \n2022-10-01 20:00:00      1026.9      1014.2      1018.5      1020.4   \n2022-10-01 21:00:00      1026.9      1013.4      1019.0      1020.1   \n2022-10-01 22:00:00      1026.6      1014.2      1018.9      1019.9   \n2022-10-01 23:00:00      1026.8      1014.9      1020.0      1020.8   \n\n                     pres_ZUQJS  pres_ZWC6W  pres_ZYC17  pres_ZYITU  \ntime                                                                 \n2019-01-01 00:00:00         NaN         NaN         NaN         NaN  \n2019-01-01 01:00:00         NaN         NaN         NaN         NaN  \n2019-01-01 02:00:00         NaN         NaN         NaN         NaN  \n2019-01-01 03:00:00         NaN         NaN         NaN         NaN  \n2019-01-01 04:00:00         NaN         NaN         NaN         NaN  \n...                         ...         ...         ...         ...  \n2022-10-01 19:00:00      1024.6      1032.3      1021.0      1020.0  \n2022-10-01 20:00:00      1024.3      1032.1      1020.6      1020.0  \n2022-10-01 21:00:00      1024.5      1032.0      1020.8      1020.0  \n2022-10-01 22:00:00      1024.9      1032.2      1021.2      1020.0  \n2022-10-01 23:00:00      1024.9      1032.8      1021.6      1021.0  \n\n[32880 rows x 16275 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>temp_04AEH</th>\n      <th>temp_0CC8G</th>\n      <th>temp_0CNUO</th>\n      <th>temp_0CO7B</th>\n      <th>temp_0FV1F</th>\n      <th>temp_0FV2W</th>\n      <th>temp_0JM7R</th>\n      <th>temp_0JPFS</th>\n      <th>temp_0NNEW</th>\n      <th>temp_0RJDR</th>\n      <th>...</th>\n      <th>pres_Z8Y0M</th>\n      <th>pres_ZFS01</th>\n      <th>pres_ZFZUV</th>\n      <th>pres_ZJ8AR</th>\n      <th>pres_ZNWZW</th>\n      <th>pres_ZRBBD</th>\n      <th>pres_ZUQJS</th>\n      <th>pres_ZWC6W</th>\n      <th>pres_ZYC17</th>\n      <th>pres_ZYITU</th>\n    </tr>\n    <tr>\n      <th>time</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2019-01-01 00:00:00</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2019-01-01 01:00:00</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2019-01-01 02:00:00</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2019-01-01 03:00:00</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2019-01-01 04:00:00</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2022-10-01 19:00:00</th>\n      <td>18.0</td>\n      <td>16.3</td>\n      <td>12.9</td>\n      <td>19.2</td>\n      <td>18.5</td>\n      <td>NaN</td>\n      <td>8.8</td>\n      <td>15.0</td>\n      <td>21.4</td>\n      <td>22.1</td>\n      <td>...</td>\n      <td>1020.0</td>\n      <td>1020.0</td>\n      <td>1027.2</td>\n      <td>1014.3</td>\n      <td>1018.6</td>\n      <td>1020.9</td>\n      <td>1024.6</td>\n      <td>1032.3</td>\n      <td>1021.0</td>\n      <td>1020.0</td>\n    </tr>\n    <tr>\n      <th>2022-10-01 20:00:00</th>\n      <td>18.0</td>\n      <td>15.5</td>\n      <td>13.4</td>\n      <td>19.2</td>\n      <td>18.4</td>\n      <td>NaN</td>\n      <td>8.4</td>\n      <td>14.4</td>\n      <td>24.0</td>\n      <td>22.5</td>\n      <td>...</td>\n      <td>1021.0</td>\n      <td>1020.2</td>\n      <td>1026.9</td>\n      <td>1014.2</td>\n      <td>1018.5</td>\n      <td>1020.4</td>\n      <td>1024.3</td>\n      <td>1032.1</td>\n      <td>1020.6</td>\n      <td>1020.0</td>\n    </tr>\n    <tr>\n      <th>2022-10-01 21:00:00</th>\n      <td>17.0</td>\n      <td>14.3</td>\n      <td>13.3</td>\n      <td>18.1</td>\n      <td>17.8</td>\n      <td>NaN</td>\n      <td>8.1</td>\n      <td>13.4</td>\n      <td>21.8</td>\n      <td>21.9</td>\n      <td>...</td>\n      <td>1020.0</td>\n      <td>1020.3</td>\n      <td>1026.9</td>\n      <td>1013.4</td>\n      <td>1019.0</td>\n      <td>1020.1</td>\n      <td>1024.5</td>\n      <td>1032.0</td>\n      <td>1020.8</td>\n      <td>1020.0</td>\n    </tr>\n    <tr>\n      <th>2022-10-01 22:00:00</th>\n      <td>14.0</td>\n      <td>13.1</td>\n      <td>13.2</td>\n      <td>17.0</td>\n      <td>16.9</td>\n      <td>NaN</td>\n      <td>7.0</td>\n      <td>11.5</td>\n      <td>21.2</td>\n      <td>23.2</td>\n      <td>...</td>\n      <td>1020.0</td>\n      <td>1020.6</td>\n      <td>1026.6</td>\n      <td>1014.2</td>\n      <td>1018.9</td>\n      <td>1019.9</td>\n      <td>1024.9</td>\n      <td>1032.2</td>\n      <td>1021.2</td>\n      <td>1020.0</td>\n    </tr>\n    <tr>\n      <th>2022-10-01 23:00:00</th>\n      <td>14.0</td>\n      <td>11.4</td>\n      <td>12.9</td>\n      <td>15.8</td>\n      <td>15.3</td>\n      <td>NaN</td>\n      <td>4.7</td>\n      <td>9.9</td>\n      <td>19.4</td>\n      <td>22.2</td>\n      <td>...</td>\n      <td>1020.0</td>\n      <td>1021.1</td>\n      <td>1026.8</td>\n      <td>1014.9</td>\n      <td>1020.0</td>\n      <td>1020.8</td>\n      <td>1024.9</td>\n      <td>1032.8</td>\n      <td>1021.6</td>\n      <td>1021.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>32880 rows × 16275 columns</p>\n</div>"
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pivoted_df = df.pivot(index='time', columns='station', values=['temp', 'dwpt','rhum','prcp','wdir','wspd','pres'])\n",
    "pivoted_df.columns = ['_'.join(col) for col in pivoted_df.columns.values]\n",
    "pivoted_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our target is Ann Arbor which is station __\"KARB0\"__, so pulling those features out. And we want to predict the weather 24 hours in the future, so need to duplicate and shift the features while doing some more basic cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                     temp_KARB0  dwpt_KARB0  rhum_KARB0  prcp_KARB0  \\\n2019-01-01 00:00:00         3.9         3.9       100.0         NaN   \n2019-01-01 01:00:00         4.4         4.0        97.0         0.5   \n2019-01-01 02:00:00         4.4         4.4       100.0         1.5   \n2019-01-01 03:00:00         7.8         7.2        96.0         NaN   \n2019-01-01 04:00:00         6.1         5.7        97.0         NaN   \n\n                     wdir_KARB0  wspd_KARB0  pres_KARB0  24 hr~temp_KARB0  \\\n2019-01-01 00:00:00        60.0         9.4         NaN              -1.1   \n2019-01-01 01:00:00         NaN         0.0       996.8              -1.1   \n2019-01-01 02:00:00         NaN         0.0       996.9              -1.7   \n2019-01-01 03:00:00       220.0        20.5       997.3              -1.7   \n2019-01-01 04:00:00       260.0        29.5       999.8              -2.2   \n\n                     24 hr~dwpt_KARB0  24 hr~rhum_KARB0  24 hr~prcp_KARB0  \\\n2019-01-01 00:00:00              -2.2              92.0               0.0   \n2019-01-01 01:00:00              -2.2              92.0               0.0   \n2019-01-01 02:00:00              -2.3              96.0               0.0   \n2019-01-01 03:00:00              -2.8              92.0               0.0   \n2019-01-01 04:00:00              -3.3              92.0               0.0   \n\n                     24 hr~wdir_KARB0  24 hr~wspd_KARB0  24 hr~pres_KARB0  \n2019-01-01 00:00:00             350.0              11.2            1025.4  \n2019-01-01 01:00:00             360.0               5.4            1026.1  \n2019-01-01 02:00:00             350.0               7.6            1026.0  \n2019-01-01 03:00:00              10.0               7.6            1025.8  \n2019-01-01 04:00:00              50.0               5.4            1025.7  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>temp_KARB0</th>\n      <th>dwpt_KARB0</th>\n      <th>rhum_KARB0</th>\n      <th>prcp_KARB0</th>\n      <th>wdir_KARB0</th>\n      <th>wspd_KARB0</th>\n      <th>pres_KARB0</th>\n      <th>24 hr~temp_KARB0</th>\n      <th>24 hr~dwpt_KARB0</th>\n      <th>24 hr~rhum_KARB0</th>\n      <th>24 hr~prcp_KARB0</th>\n      <th>24 hr~wdir_KARB0</th>\n      <th>24 hr~wspd_KARB0</th>\n      <th>24 hr~pres_KARB0</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2019-01-01 00:00:00</th>\n      <td>3.9</td>\n      <td>3.9</td>\n      <td>100.0</td>\n      <td>NaN</td>\n      <td>60.0</td>\n      <td>9.4</td>\n      <td>NaN</td>\n      <td>-1.1</td>\n      <td>-2.2</td>\n      <td>92.0</td>\n      <td>0.0</td>\n      <td>350.0</td>\n      <td>11.2</td>\n      <td>1025.4</td>\n    </tr>\n    <tr>\n      <th>2019-01-01 01:00:00</th>\n      <td>4.4</td>\n      <td>4.0</td>\n      <td>97.0</td>\n      <td>0.5</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>996.8</td>\n      <td>-1.1</td>\n      <td>-2.2</td>\n      <td>92.0</td>\n      <td>0.0</td>\n      <td>360.0</td>\n      <td>5.4</td>\n      <td>1026.1</td>\n    </tr>\n    <tr>\n      <th>2019-01-01 02:00:00</th>\n      <td>4.4</td>\n      <td>4.4</td>\n      <td>100.0</td>\n      <td>1.5</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>996.9</td>\n      <td>-1.7</td>\n      <td>-2.3</td>\n      <td>96.0</td>\n      <td>0.0</td>\n      <td>350.0</td>\n      <td>7.6</td>\n      <td>1026.0</td>\n    </tr>\n    <tr>\n      <th>2019-01-01 03:00:00</th>\n      <td>7.8</td>\n      <td>7.2</td>\n      <td>96.0</td>\n      <td>NaN</td>\n      <td>220.0</td>\n      <td>20.5</td>\n      <td>997.3</td>\n      <td>-1.7</td>\n      <td>-2.8</td>\n      <td>92.0</td>\n      <td>0.0</td>\n      <td>10.0</td>\n      <td>7.6</td>\n      <td>1025.8</td>\n    </tr>\n    <tr>\n      <th>2019-01-01 04:00:00</th>\n      <td>6.1</td>\n      <td>5.7</td>\n      <td>97.0</td>\n      <td>NaN</td>\n      <td>260.0</td>\n      <td>29.5</td>\n      <td>999.8</td>\n      <td>-2.2</td>\n      <td>-3.3</td>\n      <td>92.0</td>\n      <td>0.0</td>\n      <td>50.0</td>\n      <td>5.4</td>\n      <td>1025.7</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann_arbor_cols = [col for col in pivoted_df.columns if \"KARB0\" in col]\n",
    "ann_arbor_df = pivoted_df[ann_arbor_cols].copy()\n",
    "for col in ann_arbor_df.columns:\n",
    "    ann_arbor_df[f'24 hr~{col}'] = ann_arbor_df[col].shift(-24)\n",
    "ann_arbor_df = ann_arbor_df.rename_axis(None, axis = 0)\n",
    "ann_arbor_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We need to merge the new features with the main dataframe so we have not only the Ann Arbor measurements, but also all measurements from surrounding stations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32467, 16289)\n"
     ]
    },
    {
     "data": {
      "text/plain": "prcp_KMHN0          31731\ndwpt_KMHN0          31722\nrhum_KMHN0          31722\npres_KMHN0          31722\nwspd_KMHN0          31722\n                    ...  \nwdir_72768              0\nwdir_74480              0\nwdir_74486              0\nwdir_74490              0\n24 hr~pres_KARB0        0\nLength: 16289, dtype: int64"
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df = pd.merge(pivoted_df,ann_arbor_df, left_index=True, right_index=True)\n",
    "pred_df = pred_df[pred_df['24 hr~temp_KARB0'].notna()]\n",
    "print(pred_df.shape)\n",
    "pred_df = pred_df.interpolate(method ='linear', limit_direction ='forward')\n",
    "\n",
    "pred_df.isna().sum(axis=0).sort_values(ascending=False)\n",
    "# pd.cut(s, 10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### There are a lot of features with excessive amounts of null values to get rid of. Dropping any with more than 500 missing values still leaves a sufficient number of features for predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(31967, 10445)"
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_drop = []\n",
    "for col in pred_df.columns:\n",
    "    num = pred_df[col].isna().sum()\n",
    "    if num > 500:\n",
    "        # print(f\"{col} has {num} missing values\")\n",
    "        to_drop.append(col)\n",
    "pred_df.drop(columns=to_drop,inplace=True)\n",
    "pred_df.dropna(inplace=True)\n",
    "pred_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now our target will be the '-24hr~temp_KARB0' column, and our features to use in our first prediction model will be all of the measurements at every surrounding station 24 hours prior to our target.\n",
    "This cell will run 5 fold cross-validate on our 3 chosen regression models (Extra Trees Regressor, Lasso Regressor, and Tweedie Regressor). This will show how the average accuracy scores compare across these models on this data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn [49], line 19\u001B[0m\n\u001B[0;32m     13\u001B[0m models \u001B[38;5;241m=\u001B[39m {\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mExtra Trees Regressor\u001B[39m\u001B[38;5;124m'\u001B[39m:xt_reg,\n\u001B[0;32m     14\u001B[0m           \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mLasso Regressor\u001B[39m\u001B[38;5;124m'\u001B[39m:lasso_reg,\n\u001B[0;32m     15\u001B[0m           \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mTweedie Regressor\u001B[39m\u001B[38;5;124m'\u001B[39m:tw_reg,\n\u001B[0;32m     16\u001B[0m           \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mDummy Regressor\u001B[39m\u001B[38;5;124m'\u001B[39m:dummy_reg}\n\u001B[0;32m     17\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m key, value \u001B[38;5;129;01min\u001B[39;00m models\u001B[38;5;241m.\u001B[39mitems():\n\u001B[0;32m     18\u001B[0m     \u001B[38;5;66;03m# value = make_pipeline(StandardScaler(), value)\u001B[39;00m\n\u001B[1;32m---> 19\u001B[0m     cv_results \u001B[38;5;241m=\u001B[39m \u001B[43mcross_validate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcv\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m5\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m     20\u001B[0m     \u001B[38;5;28mprint\u001B[39m(key)\n\u001B[0;32m     21\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mMean accuracy score: \u001B[39m\u001B[38;5;124m\"\u001B[39m, end\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32mc:\\users\\jesse\\onedrive\\documents\\homework\\mich\\521\\ms2_git\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:266\u001B[0m, in \u001B[0;36mcross_validate\u001B[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001B[0m\n\u001B[0;32m    263\u001B[0m \u001B[38;5;66;03m# We clone the estimator to make sure that all the folds are\u001B[39;00m\n\u001B[0;32m    264\u001B[0m \u001B[38;5;66;03m# independent, and that it is pickle-able.\u001B[39;00m\n\u001B[0;32m    265\u001B[0m parallel \u001B[38;5;241m=\u001B[39m Parallel(n_jobs\u001B[38;5;241m=\u001B[39mn_jobs, verbose\u001B[38;5;241m=\u001B[39mverbose, pre_dispatch\u001B[38;5;241m=\u001B[39mpre_dispatch)\n\u001B[1;32m--> 266\u001B[0m results \u001B[38;5;241m=\u001B[39m \u001B[43mparallel\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    267\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdelayed\u001B[49m\u001B[43m(\u001B[49m\u001B[43m_fit_and_score\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    268\u001B[0m \u001B[43m        \u001B[49m\u001B[43mclone\u001B[49m\u001B[43m(\u001B[49m\u001B[43mestimator\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    269\u001B[0m \u001B[43m        \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    270\u001B[0m \u001B[43m        \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    271\u001B[0m \u001B[43m        \u001B[49m\u001B[43mscorers\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    272\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtrain\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    273\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtest\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    274\u001B[0m \u001B[43m        \u001B[49m\u001B[43mverbose\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    275\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    276\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfit_params\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    277\u001B[0m \u001B[43m        \u001B[49m\u001B[43mreturn_train_score\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_train_score\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    278\u001B[0m \u001B[43m        \u001B[49m\u001B[43mreturn_times\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    279\u001B[0m \u001B[43m        \u001B[49m\u001B[43mreturn_estimator\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_estimator\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    280\u001B[0m \u001B[43m        \u001B[49m\u001B[43merror_score\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43merror_score\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    281\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    282\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mtrain\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mcv\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msplit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgroups\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    283\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    285\u001B[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001B[0;32m    287\u001B[0m \u001B[38;5;66;03m# For callabe scoring, the return type is only know after calling. If the\u001B[39;00m\n\u001B[0;32m    288\u001B[0m \u001B[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001B[39;00m\n\u001B[0;32m    289\u001B[0m \u001B[38;5;66;03m# the correct key.\u001B[39;00m\n",
      "File \u001B[1;32mc:\\users\\jesse\\onedrive\\documents\\homework\\mich\\521\\ms2_git\\lib\\site-packages\\joblib\\parallel.py:1046\u001B[0m, in \u001B[0;36mParallel.__call__\u001B[1;34m(self, iterable)\u001B[0m\n\u001B[0;32m   1043\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdispatch_one_batch(iterator):\n\u001B[0;32m   1044\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_iterating \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_original_iterator \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m-> 1046\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdispatch_one_batch\u001B[49m\u001B[43m(\u001B[49m\u001B[43miterator\u001B[49m\u001B[43m)\u001B[49m:\n\u001B[0;32m   1047\u001B[0m     \u001B[38;5;28;01mpass\u001B[39;00m\n\u001B[0;32m   1049\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m pre_dispatch \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mall\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mor\u001B[39;00m n_jobs \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m   1050\u001B[0m     \u001B[38;5;66;03m# The iterable was consumed all at once by the above for loop.\u001B[39;00m\n\u001B[0;32m   1051\u001B[0m     \u001B[38;5;66;03m# No need to wait for async callbacks to trigger to\u001B[39;00m\n\u001B[0;32m   1052\u001B[0m     \u001B[38;5;66;03m# consumption.\u001B[39;00m\n",
      "File \u001B[1;32mc:\\users\\jesse\\onedrive\\documents\\homework\\mich\\521\\ms2_git\\lib\\site-packages\\joblib\\parallel.py:861\u001B[0m, in \u001B[0;36mParallel.dispatch_one_batch\u001B[1;34m(self, iterator)\u001B[0m\n\u001B[0;32m    859\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[0;32m    860\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 861\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_dispatch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtasks\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    862\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "File \u001B[1;32mc:\\users\\jesse\\onedrive\\documents\\homework\\mich\\521\\ms2_git\\lib\\site-packages\\joblib\\parallel.py:779\u001B[0m, in \u001B[0;36mParallel._dispatch\u001B[1;34m(self, batch)\u001B[0m\n\u001B[0;32m    777\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock:\n\u001B[0;32m    778\u001B[0m     job_idx \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jobs)\n\u001B[1;32m--> 779\u001B[0m     job \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_backend\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply_async\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcallback\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcb\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    780\u001B[0m     \u001B[38;5;66;03m# A job can complete so quickly than its callback is\u001B[39;00m\n\u001B[0;32m    781\u001B[0m     \u001B[38;5;66;03m# called before we get here, causing self._jobs to\u001B[39;00m\n\u001B[0;32m    782\u001B[0m     \u001B[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001B[39;00m\n\u001B[0;32m    783\u001B[0m     \u001B[38;5;66;03m# used (rather than .append) in the following line\u001B[39;00m\n\u001B[0;32m    784\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jobs\u001B[38;5;241m.\u001B[39minsert(job_idx, job)\n",
      "File \u001B[1;32mc:\\users\\jesse\\onedrive\\documents\\homework\\mich\\521\\ms2_git\\lib\\site-packages\\joblib\\_parallel_backends.py:208\u001B[0m, in \u001B[0;36mSequentialBackend.apply_async\u001B[1;34m(self, func, callback)\u001B[0m\n\u001B[0;32m    206\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mapply_async\u001B[39m(\u001B[38;5;28mself\u001B[39m, func, callback\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[0;32m    207\u001B[0m     \u001B[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001B[39;00m\n\u001B[1;32m--> 208\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[43mImmediateResult\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    209\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m callback:\n\u001B[0;32m    210\u001B[0m         callback(result)\n",
      "File \u001B[1;32mc:\\users\\jesse\\onedrive\\documents\\homework\\mich\\521\\ms2_git\\lib\\site-packages\\joblib\\_parallel_backends.py:572\u001B[0m, in \u001B[0;36mImmediateResult.__init__\u001B[1;34m(self, batch)\u001B[0m\n\u001B[0;32m    569\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, batch):\n\u001B[0;32m    570\u001B[0m     \u001B[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001B[39;00m\n\u001B[0;32m    571\u001B[0m     \u001B[38;5;66;03m# arguments in memory\u001B[39;00m\n\u001B[1;32m--> 572\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mresults \u001B[38;5;241m=\u001B[39m \u001B[43mbatch\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mc:\\users\\jesse\\onedrive\\documents\\homework\\mich\\521\\ms2_git\\lib\\site-packages\\joblib\\parallel.py:262\u001B[0m, in \u001B[0;36mBatchedCalls.__call__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    258\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    259\u001B[0m     \u001B[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001B[39;00m\n\u001B[0;32m    260\u001B[0m     \u001B[38;5;66;03m# change the default number of processes to -1\u001B[39;00m\n\u001B[0;32m    261\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m parallel_backend(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backend, n_jobs\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_n_jobs):\n\u001B[1;32m--> 262\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m [func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    263\u001B[0m                 \u001B[38;5;28;01mfor\u001B[39;00m func, args, kwargs \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mitems]\n",
      "File \u001B[1;32mc:\\users\\jesse\\onedrive\\documents\\homework\\mich\\521\\ms2_git\\lib\\site-packages\\joblib\\parallel.py:262\u001B[0m, in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m    258\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    259\u001B[0m     \u001B[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001B[39;00m\n\u001B[0;32m    260\u001B[0m     \u001B[38;5;66;03m# change the default number of processes to -1\u001B[39;00m\n\u001B[0;32m    261\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m parallel_backend(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backend, n_jobs\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_n_jobs):\n\u001B[1;32m--> 262\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m [func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    263\u001B[0m                 \u001B[38;5;28;01mfor\u001B[39;00m func, args, kwargs \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mitems]\n",
      "File \u001B[1;32mc:\\users\\jesse\\onedrive\\documents\\homework\\mich\\521\\ms2_git\\lib\\site-packages\\sklearn\\utils\\fixes.py:117\u001B[0m, in \u001B[0;36m_FuncWrapper.__call__\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m    115\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m    116\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m config_context(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig):\n\u001B[1;32m--> 117\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfunction(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32mc:\\users\\jesse\\onedrive\\documents\\homework\\mich\\521\\ms2_git\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686\u001B[0m, in \u001B[0;36m_fit_and_score\u001B[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001B[0m\n\u001B[0;32m    684\u001B[0m         estimator\u001B[38;5;241m.\u001B[39mfit(X_train, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mfit_params)\n\u001B[0;32m    685\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 686\u001B[0m         estimator\u001B[38;5;241m.\u001B[39mfit(X_train, y_train, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mfit_params)\n\u001B[0;32m    688\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m:\n\u001B[0;32m    689\u001B[0m     \u001B[38;5;66;03m# Note fit time as time until error\u001B[39;00m\n\u001B[0;32m    690\u001B[0m     fit_time \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime() \u001B[38;5;241m-\u001B[39m start_time\n",
      "File \u001B[1;32mc:\\users\\jesse\\onedrive\\documents\\homework\\mich\\521\\ms2_git\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:476\u001B[0m, in \u001B[0;36mBaseForest.fit\u001B[1;34m(self, X, y, sample_weight)\u001B[0m\n\u001B[0;32m    465\u001B[0m trees \u001B[38;5;241m=\u001B[39m [\n\u001B[0;32m    466\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_make_estimator(append\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m, random_state\u001B[38;5;241m=\u001B[39mrandom_state)\n\u001B[0;32m    467\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(n_more_estimators)\n\u001B[0;32m    468\u001B[0m ]\n\u001B[0;32m    470\u001B[0m \u001B[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001B[39;00m\n\u001B[0;32m    471\u001B[0m \u001B[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001B[39;00m\n\u001B[0;32m    472\u001B[0m \u001B[38;5;66;03m# making threading more efficient than multiprocessing in\u001B[39;00m\n\u001B[0;32m    473\u001B[0m \u001B[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001B[39;00m\n\u001B[0;32m    474\u001B[0m \u001B[38;5;66;03m# parallel_backend contexts set at a higher level,\u001B[39;00m\n\u001B[0;32m    475\u001B[0m \u001B[38;5;66;03m# since correctness does not rely on using threads.\u001B[39;00m\n\u001B[1;32m--> 476\u001B[0m trees \u001B[38;5;241m=\u001B[39m \u001B[43mParallel\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    477\u001B[0m \u001B[43m    \u001B[49m\u001B[43mn_jobs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mn_jobs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    478\u001B[0m \u001B[43m    \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mverbose\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    479\u001B[0m \u001B[43m    \u001B[49m\u001B[43mprefer\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mthreads\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m    480\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    481\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdelayed\u001B[49m\u001B[43m(\u001B[49m\u001B[43m_parallel_build_trees\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    482\u001B[0m \u001B[43m        \u001B[49m\u001B[43mt\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    483\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbootstrap\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    484\u001B[0m \u001B[43m        \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    485\u001B[0m \u001B[43m        \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    486\u001B[0m \u001B[43m        \u001B[49m\u001B[43msample_weight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    487\u001B[0m \u001B[43m        \u001B[49m\u001B[43mi\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    488\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mtrees\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    489\u001B[0m \u001B[43m        \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mverbose\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    490\u001B[0m \u001B[43m        \u001B[49m\u001B[43mclass_weight\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mclass_weight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    491\u001B[0m \u001B[43m        \u001B[49m\u001B[43mn_samples_bootstrap\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mn_samples_bootstrap\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    492\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    493\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mi\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mt\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43menumerate\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mtrees\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    494\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    496\u001B[0m \u001B[38;5;66;03m# Collect newly grown trees\u001B[39;00m\n\u001B[0;32m    497\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mestimators_\u001B[38;5;241m.\u001B[39mextend(trees)\n",
      "File \u001B[1;32mc:\\users\\jesse\\onedrive\\documents\\homework\\mich\\521\\ms2_git\\lib\\site-packages\\joblib\\parallel.py:1046\u001B[0m, in \u001B[0;36mParallel.__call__\u001B[1;34m(self, iterable)\u001B[0m\n\u001B[0;32m   1043\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdispatch_one_batch(iterator):\n\u001B[0;32m   1044\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_iterating \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_original_iterator \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m-> 1046\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdispatch_one_batch\u001B[49m\u001B[43m(\u001B[49m\u001B[43miterator\u001B[49m\u001B[43m)\u001B[49m:\n\u001B[0;32m   1047\u001B[0m     \u001B[38;5;28;01mpass\u001B[39;00m\n\u001B[0;32m   1049\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m pre_dispatch \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mall\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mor\u001B[39;00m n_jobs \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m   1050\u001B[0m     \u001B[38;5;66;03m# The iterable was consumed all at once by the above for loop.\u001B[39;00m\n\u001B[0;32m   1051\u001B[0m     \u001B[38;5;66;03m# No need to wait for async callbacks to trigger to\u001B[39;00m\n\u001B[0;32m   1052\u001B[0m     \u001B[38;5;66;03m# consumption.\u001B[39;00m\n",
      "File \u001B[1;32mc:\\users\\jesse\\onedrive\\documents\\homework\\mich\\521\\ms2_git\\lib\\site-packages\\joblib\\parallel.py:861\u001B[0m, in \u001B[0;36mParallel.dispatch_one_batch\u001B[1;34m(self, iterator)\u001B[0m\n\u001B[0;32m    859\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[0;32m    860\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 861\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_dispatch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtasks\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    862\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "File \u001B[1;32mc:\\users\\jesse\\onedrive\\documents\\homework\\mich\\521\\ms2_git\\lib\\site-packages\\joblib\\parallel.py:779\u001B[0m, in \u001B[0;36mParallel._dispatch\u001B[1;34m(self, batch)\u001B[0m\n\u001B[0;32m    777\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock:\n\u001B[0;32m    778\u001B[0m     job_idx \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jobs)\n\u001B[1;32m--> 779\u001B[0m     job \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_backend\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply_async\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcallback\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcb\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    780\u001B[0m     \u001B[38;5;66;03m# A job can complete so quickly than its callback is\u001B[39;00m\n\u001B[0;32m    781\u001B[0m     \u001B[38;5;66;03m# called before we get here, causing self._jobs to\u001B[39;00m\n\u001B[0;32m    782\u001B[0m     \u001B[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001B[39;00m\n\u001B[0;32m    783\u001B[0m     \u001B[38;5;66;03m# used (rather than .append) in the following line\u001B[39;00m\n\u001B[0;32m    784\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jobs\u001B[38;5;241m.\u001B[39minsert(job_idx, job)\n",
      "File \u001B[1;32mc:\\users\\jesse\\onedrive\\documents\\homework\\mich\\521\\ms2_git\\lib\\site-packages\\joblib\\_parallel_backends.py:208\u001B[0m, in \u001B[0;36mSequentialBackend.apply_async\u001B[1;34m(self, func, callback)\u001B[0m\n\u001B[0;32m    206\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mapply_async\u001B[39m(\u001B[38;5;28mself\u001B[39m, func, callback\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[0;32m    207\u001B[0m     \u001B[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001B[39;00m\n\u001B[1;32m--> 208\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[43mImmediateResult\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    209\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m callback:\n\u001B[0;32m    210\u001B[0m         callback(result)\n",
      "File \u001B[1;32mc:\\users\\jesse\\onedrive\\documents\\homework\\mich\\521\\ms2_git\\lib\\site-packages\\joblib\\_parallel_backends.py:572\u001B[0m, in \u001B[0;36mImmediateResult.__init__\u001B[1;34m(self, batch)\u001B[0m\n\u001B[0;32m    569\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, batch):\n\u001B[0;32m    570\u001B[0m     \u001B[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001B[39;00m\n\u001B[0;32m    571\u001B[0m     \u001B[38;5;66;03m# arguments in memory\u001B[39;00m\n\u001B[1;32m--> 572\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mresults \u001B[38;5;241m=\u001B[39m \u001B[43mbatch\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mc:\\users\\jesse\\onedrive\\documents\\homework\\mich\\521\\ms2_git\\lib\\site-packages\\joblib\\parallel.py:262\u001B[0m, in \u001B[0;36mBatchedCalls.__call__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    258\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    259\u001B[0m     \u001B[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001B[39;00m\n\u001B[0;32m    260\u001B[0m     \u001B[38;5;66;03m# change the default number of processes to -1\u001B[39;00m\n\u001B[0;32m    261\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m parallel_backend(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backend, n_jobs\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_n_jobs):\n\u001B[1;32m--> 262\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m [func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    263\u001B[0m                 \u001B[38;5;28;01mfor\u001B[39;00m func, args, kwargs \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mitems]\n",
      "File \u001B[1;32mc:\\users\\jesse\\onedrive\\documents\\homework\\mich\\521\\ms2_git\\lib\\site-packages\\joblib\\parallel.py:262\u001B[0m, in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m    258\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    259\u001B[0m     \u001B[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001B[39;00m\n\u001B[0;32m    260\u001B[0m     \u001B[38;5;66;03m# change the default number of processes to -1\u001B[39;00m\n\u001B[0;32m    261\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m parallel_backend(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backend, n_jobs\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_n_jobs):\n\u001B[1;32m--> 262\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m [func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    263\u001B[0m                 \u001B[38;5;28;01mfor\u001B[39;00m func, args, kwargs \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mitems]\n",
      "File \u001B[1;32mc:\\users\\jesse\\onedrive\\documents\\homework\\mich\\521\\ms2_git\\lib\\site-packages\\sklearn\\utils\\fixes.py:117\u001B[0m, in \u001B[0;36m_FuncWrapper.__call__\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m    115\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m    116\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m config_context(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig):\n\u001B[1;32m--> 117\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfunction(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32mc:\\users\\jesse\\onedrive\\documents\\homework\\mich\\521\\ms2_git\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:191\u001B[0m, in \u001B[0;36m_parallel_build_trees\u001B[1;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001B[0m\n\u001B[0;32m    189\u001B[0m     tree\u001B[38;5;241m.\u001B[39mfit(X, y, sample_weight\u001B[38;5;241m=\u001B[39mcurr_sample_weight, check_input\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[0;32m    190\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 191\u001B[0m     \u001B[43mtree\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msample_weight\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msample_weight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcheck_input\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[0;32m    193\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m tree\n",
      "File \u001B[1;32mc:\\users\\jesse\\onedrive\\documents\\homework\\mich\\521\\ms2_git\\lib\\site-packages\\sklearn\\tree\\_classes.py:1342\u001B[0m, in \u001B[0;36mDecisionTreeRegressor.fit\u001B[1;34m(self, X, y, sample_weight, check_input)\u001B[0m\n\u001B[0;32m   1313\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfit\u001B[39m(\u001B[38;5;28mself\u001B[39m, X, y, sample_weight\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, check_input\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m):\n\u001B[0;32m   1314\u001B[0m     \u001B[38;5;124;03m\"\"\"Build a decision tree regressor from the training set (X, y).\u001B[39;00m\n\u001B[0;32m   1315\u001B[0m \n\u001B[0;32m   1316\u001B[0m \u001B[38;5;124;03m    Parameters\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1339\u001B[0m \u001B[38;5;124;03m        Fitted estimator.\u001B[39;00m\n\u001B[0;32m   1340\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m-> 1342\u001B[0m     \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1343\u001B[0m \u001B[43m        \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1344\u001B[0m \u001B[43m        \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1345\u001B[0m \u001B[43m        \u001B[49m\u001B[43msample_weight\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msample_weight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1346\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcheck_input\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcheck_input\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1347\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1348\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\n",
      "File \u001B[1;32mc:\\users\\jesse\\onedrive\\documents\\homework\\mich\\521\\ms2_git\\lib\\site-packages\\sklearn\\tree\\_classes.py:458\u001B[0m, in \u001B[0;36mBaseDecisionTree.fit\u001B[1;34m(self, X, y, sample_weight, check_input)\u001B[0m\n\u001B[0;32m    447\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    448\u001B[0m     builder \u001B[38;5;241m=\u001B[39m BestFirstTreeBuilder(\n\u001B[0;32m    449\u001B[0m         splitter,\n\u001B[0;32m    450\u001B[0m         min_samples_split,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    455\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmin_impurity_decrease,\n\u001B[0;32m    456\u001B[0m     )\n\u001B[1;32m--> 458\u001B[0m \u001B[43mbuilder\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbuild\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtree_\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msample_weight\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    460\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_outputs_ \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m is_classifier(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    461\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_classes_ \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_classes_[\u001B[38;5;241m0\u001B[39m]\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# from sklearn.pipeline import make_pipeline\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# from sklearn.preprocessing import RobustScaler\n",
    "X_cols = [col for col in pred_df.columns if \"~\" not in col]\n",
    "X = pred_df[X_cols]\n",
    "y = pred_df['24 hr~temp_KARB0']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=696)\n",
    "xt_reg = ExtraTreesRegressor(random_state=696)\n",
    "lasso_reg = linear_model.Lasso(alpha=0.1,max_iter=1500)\n",
    "tw_reg = linear_model.TweedieRegressor(max_iter=250)\n",
    "dummy_reg = DummyRegressor(strategy=\"median\")\n",
    "models = {'Extra Trees Regressor':xt_reg,\n",
    "          'Lasso Regressor':lasso_reg,\n",
    "          'Tweedie Regressor':tw_reg,\n",
    "          'Dummy Regressor':dummy_reg}\n",
    "for key, value in models.items():\n",
    "    # value = make_pipeline(StandardScaler(), value)\n",
    "    cv_results = cross_validate(value, X_train, y_train, cv=5)\n",
    "    print(key)\n",
    "    print(\"Mean accuracy score: \", end=\"\")\n",
    "    print(round(cv_results['test_score'].mean(),3), end=\"\")\n",
    "    print(\", best accuracy score: \", end=\"\")\n",
    "    print(round(cv_results['test_score'].max(),3), end=\"\")\n",
    "    print(\", with std dev of: \", end=\"\")\n",
    "    print(round(cv_results['test_score'].std(),3))\n",
    "    print(\"Mean training time: \", end=\"\")\n",
    "    print(round(cv_results['score_time'].mean(),3))\n",
    "    print(f\"Score on hold out set: {round(value.fit(X_train, y_train).score(X_test, y_test),3)}\")\n",
    "    print(\"**************\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examine the feature importances in the best performing model (Extra Trees Regressor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "feature_importance_df = pd.DataFrame([X.columns, xt_reg.feature_importances_]).transpose()\n",
    "feature_importance_df.columns = ['Feature', 'Importance']\n",
    "feature_importance_df.sort_values('Importance',ascending=False,inplace=True)\n",
    "feature_importance_df.to_csv(\"full_basic_features.csv\",index=False)\n",
    "feature_importance_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import altair as alt\n",
    "alt.Chart(feature_importance_df[:5]).mark_bar().encode(\n",
    "    x=alt.X('Importance:Q', axis=alt.Axis(format=\"%\", tickSize=0, labelFontSize=12)),\n",
    "    y=alt.Y(\n",
    "        'Feature:N', sort=list(feature_importance_df[:5].Feature), title=\"\",\n",
    "        axis=alt.Axis(tickSize=0, labelFontSize=12, labelPadding=10)),\n",
    ").properties(\n",
    "    height=200\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyper-parameter tuning the Extra Trees Regressor\n",
    "5 fold cross validate looking for the optimized estimators, depth, sample split, and sample leaf parameters. Evaluating the 'best' based on the mean squared error achieved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# %%timeit -r 1 -n 1\n",
    "space  = [Integer(100,200, name='n_estimators'),\n",
    "          Integer(1, 50, name='max_depth'),\n",
    "          Integer(2, 100, name='min_samples_split'),\n",
    "          Integer(1, 100, name='min_samples_leaf')]\n",
    "\n",
    "@use_named_args(space)\n",
    "def objective(**params):\n",
    "    xt_reg.set_params(**params)\n",
    "\n",
    "    return -np.mean(cross_val_score(xt_reg, X_train, y_train, cv=5, n_jobs=-1))\n",
    "\n",
    "res_gp = gp_minimize(objective, space, n_calls=15, random_state=696)\n",
    "\n",
    "print(f\"Best score: {res_gp.fun}\")\n",
    "print(\"Best parameters:\")\n",
    "print(f\" - n-estimators= {res_gp.x[0]}\")\n",
    "print(f\" - max_depth= {res_gp.x[1]}\")\n",
    "print(f\" - min_samples_split= {res_gp.x[2]}\")\n",
    "print(f\" - min_samples_leaf=  {res_gp.x[3]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the convergence for the above hypertuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plot_convergence(res_gp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final re-run of the Extra Trees Model with the tuned hyperparameters\n",
    "There is a very minor improvement on the accuracy score, with some pretty significant increases in training time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "xt_reg = ExtraTreesRegressor(n_estimators=res_gp.x[0],\n",
    "                             max_depth=res_gp.x[1],\n",
    "                             min_samples_split=res_gp.x[2],\n",
    "                             min_samples_leaf=res_gp.x[3],\n",
    "                             random_state=696,n_jobs=-1\n",
    "                            )\n",
    "models = {'Extra Trees Regressor':xt_reg}\n",
    "for key, value in models.items():\n",
    "    cv_results = cross_validate(value, X_train, y_train, cv=5,n_jobs=-1)\n",
    "    print(key)\n",
    "    print(\"Mean accuracy score: \", end=\"\")\n",
    "    print(round(cv_results['test_score'].mean(),3), end=\"\")\n",
    "    print(\", best accuracy score: \", end=\"\")\n",
    "    print(round(cv_results['test_score'].max(),3), end=\"\")\n",
    "    print(\", with std dev of: \", end=\"\")\n",
    "    print(round(cv_results['test_score'].std(),3))\n",
    "    print(\"Mean training time: \", end=\"\")\n",
    "    print(round(cv_results['score_time'].mean(),3))\n",
    "    print(f\"Score on hold out set: {round(value.fit(X_train, y_train).score(X_test, y_test),3)}\")\n",
    "    print(\"**************\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unfinished Work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.DataFrame()\n",
    "final_df['Actual'] = y.values\n",
    "final_df['XT-pred'] = xt_reg.predict(X)\n",
    "final_df['Lo-pred'] = lasso_reg.predict(X)\n",
    "final_df['Tw-pred'] = tw_reg.predict(X)\n",
    "final_df['Dum-pred'] = dummy_reg.predict(X)\n",
    "final_df['TimeStamp'] = pred_df.index\n",
    "# final_df = final_df.melt(id_vars='TimeStamp')\n",
    "final_df.to_csv('full_basic_predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}